# API Server Configuration
PORT=3000

# AI Configuration (Local LLM)
AI_API_URL=http://127.0.0.1:1234/v1/chat/completions
AI_MODEL=llama-3.2-3b-instruct

# CORS Configuration (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:4200